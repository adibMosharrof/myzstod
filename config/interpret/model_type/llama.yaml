model_name: meta-llama/Llama-3.2-1B-Instruct
model_path: ""
# model_path: outputs/probing/2024-10-31/15-32-37_opt67b/results/checkpoint-250
train_batch_size: 1
eval_batch_size: 1
test_batch_size: 5
gradient_accumulation_steps: 32
eval_accumulation_steps: 32
quantization: false
quantization_dtype: 4
learning_rate: 1e-3
model_log_name: llama1b
context_type: gpt_api_call