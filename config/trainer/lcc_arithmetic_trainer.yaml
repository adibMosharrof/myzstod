pretrain_epochs: 30
train_epochs: 40
pretrain_batch_size: 6
train_batch_size: 3
eval_batch_size: 6
test_batch_size: 80
max_token_len: 1024
test_prompt_max_len: 750
raw_data_root: data/dstc8-schema-guided-dialogue/
project_root: /project/msi290_uksr/generative_tod
num_dialogs: 
  - 127
  - 20
  - 34
# num_dialogs: 
#   - 5
#   - 5
#   - 10
# overwrite:
#   - true
#   - true
#   - true
should_test: true
train_domain_settings:
  - Restaurants_1
dev_domain_settings:
  - Restaurants_2
test_domain_settings:
  - [Restaurants_2]
wandb:
  project: ZSTod
  entity: adibm
  notes: arithmetic restaurants 
  task: arithmetic
model_name: distilgpt2
fp16: true
gradient_accumulation_steps: 4